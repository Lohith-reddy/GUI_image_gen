{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opencv-python) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.24.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:52:01.476625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 15:52:02.239325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras.layers as L\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import concatenate\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading files from s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3_client =boto3.client('s3')\n",
    "s3_bucket_name='recolourise'\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id= 'YOUR_ACCESS_KEY_ID',\n",
    "                    aws_secret_access_key='YOUR_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_uri = 's3://recolorising/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the contents of the uri\n",
    "# !aws s3 ls $training_data_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from s3fs.core import S3FileSystem\n",
    "s3 = S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_key = 'processed/train.npy'\n",
    "test_key = 'processed/test.npy'\n",
    "gray_test_key = 'processed/gray_test.npy'\n",
    "gray_train_key = 'processed/gray_train.npy'\n",
    "bucket = 'recolorising'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = np.load(s3.open('{}/{}'.format(bucket, train_key)))\n",
    "test = np.load(s3.open('{}/{}'.format(bucket, test_key)))\n",
    "gray_test = np.load(s3.open('{}/{}'.format(bucket, gray_test_key)))\n",
    "gray_train = np.load(s3.open('{}/{}'.format(bucket, gray_train_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 128, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = full_img[2,:,:,:]\n",
    "#img = cv2.cvtColor(np.array(img), cv2.COLOR_Lab2RGB)\n",
    "plt.imshow(np.array(img).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COnverting RGB back into Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Unet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    Xinpt = L.Input([None, None, 1])\n",
    "    X0 = L.Conv2D(64, (3, 3), padding='same')(Xinpt)\n",
    "    X0 = L.BatchNormalization()(X0)\n",
    "    X0 = L.LeakyReLU(alpha=0.2)(X0)    #l,b,64\n",
    "    X0 = L.Conv2D(64, (3, 3), strides=1, padding='same')(X0)\n",
    "    X0 = L.BatchNormalization()(X0)\n",
    "    X0 = L.LeakyReLU(alpha=0.2)(X0)    #l,b,64\n",
    "    \n",
    "    X1 = L.MaxPool2D((2, 2), strides=2)(X0)    #l/2,b/2,64\n",
    "    X1 = L.Conv2D(128, (3, 3), padding='same')(X1)\n",
    "    X1 = L.BatchNormalization()(X1)\n",
    "    X1 = L.LeakyReLU(alpha=0.2)(X1)\n",
    "    X1 = L.Conv2D(128, (3, 3), padding='same')(X1)\n",
    "    X1 = L.BatchNormalization()(X1)\n",
    "    X1 = L.LeakyReLU(alpha=0.2)(X1)    #l/2,b/2,128\n",
    "    \n",
    "    X2 = L.MaxPool2D((2, 2), strides=2)(X1)    #l/4,b/4,128\n",
    "    X2 = L.Conv2D(256, (3, 3), padding='same')(X2)\n",
    "    X2 = L.BatchNormalization()(X2)\n",
    "    X2 = L.LeakyReLU(alpha=0.2)(X2)\n",
    "    X2 = L.Conv2D(256, (3, 3), padding='same')(X2)\n",
    "    X2 = L.BatchNormalization()(X2)\n",
    "    X2 = L.LeakyReLU(alpha=0.2)(X2)    #l/4,b/4,256\n",
    "    \n",
    "    X3 = L.MaxPool2D((2, 2), strides=2)(X2)    #l/8,b/8,256\n",
    "    X3 = L.Conv2D(512, (3, 3), padding='same')(X3)\n",
    "    X3 = L.BatchNormalization()(X3)\n",
    "    X3 = L.LeakyReLU(alpha=0.2)(X3)\n",
    "    X3 = L.Conv2D(512, (3, 3), padding='same')(X3)\n",
    "    X3 = L.BatchNormalization()(X3)\n",
    "    X3 = L.LeakyReLU(alpha=0.2)(X3)    #l/8,b/8,512\n",
    "    \n",
    "    X4 = L.MaxPool2D((2, 2), strides=2)(X3)    #l/16,b/16,512\n",
    "    X4 = L.Conv2D(1024, (3, 3), padding='same')(X4)\n",
    "    X4 = L.BatchNormalization()(X4)\n",
    "    X4 = L.LeakyReLU(alpha=0.2)(X4)\n",
    "    X4 = L.Conv2D(1024, (3, 3), padding='same')(X4)\n",
    "    X4 = L.BatchNormalization()(X4)\n",
    "    X4 = L.LeakyReLU(alpha=0.2)(X4)    #l/16,b/16,1024\n",
    "    \n",
    "    X4 = L.Conv2DTranspose(512, (2, 2), strides=2)(X4)    #l/8,b/8,512\n",
    "    X4 = L.Concatenate()([X3, X4])     #l/8,b/8,1024\n",
    "    X4 = L.Conv2D(512, (3, 3), padding='same')(X4)\n",
    "    X4 = L.BatchNormalization()(X4)\n",
    "    X4 = L.Activation('relu')(X4)\n",
    "    X4 = L.Conv2D(512, (3, 3), padding='same')(X4)\n",
    "    X4 = L.BatchNormalization()(X4)\n",
    "    X4 = L.Activation('relu')(X4)    #l/8,b/8,512\n",
    "    \n",
    "    X3 = L.Conv2DTranspose(256, (2, 2), strides=2)(X4)    #l/4,b.4,256\n",
    "    X3 = L.Concatenate()([X2, X3])     #l/4,b/4,512\n",
    "    X3 = L.Conv2D(256, (3, 3), padding='same')(X3)\n",
    "    X3 = L.BatchNormalization()(X3)\n",
    "    X3 = L.Activation('relu')(X3)\n",
    "    X3 = L.Conv2D(256, (3, 3), padding='same')(X3)\n",
    "    X3 = L.BatchNormalization()(X3)\n",
    "    X3 = L.Activation('relu')(X3)    #l/4,b/4,256\n",
    "    \n",
    "    X2 = L.Conv2DTranspose(128, (2, 2), strides=2)(X3)    #l/2,b/2,128\n",
    "    X2 = L.Concatenate()([X1, X2])     #l/2,b/2,256\n",
    "    X2 = L.Conv2D(128, (3, 3), padding='same')(X2)\n",
    "    X2 = L.BatchNormalization()(X2)\n",
    "    X2 = L.Activation('relu')(X2)\n",
    "    X2 = L.Conv2D(128, (3, 3), padding='same')(X2)\n",
    "    X2 = L.BatchNormalization()(X2)\n",
    "    X2 = L.Activation('relu')(X2)   #l/2,b/2,128\n",
    "    \n",
    "    X1 = L.Conv2DTranspose(64, (2, 2), strides=2)(X2)    #l,b,64\n",
    "    X1 = L.Concatenate()([X0, X1])    #l,b,128\n",
    "    X1 = L.Conv2D(64, (3, 3), padding='same')(X1)\n",
    "    X1 = L.BatchNormalization()(X1)\n",
    "    X1 = L.Activation('relu')(X1)\n",
    "    X1 = L.Conv2D(64, (3, 3), padding='same')(X1)\n",
    "    X1 = L.BatchNormalization()(X1)\n",
    "    X1 = L.Activation('relu')(X1)    #l,b,64\n",
    "    \n",
    "    X0 = L.Conv2D(3, (1, 1), strides=1)(X1)     #l,b,3 \n",
    "    model = Model(inputs=Xinpt, outputs=X0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 15:54:09.984400: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "model.compile('adam', loss='mean_squared_error', metrics=['mae', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, bsize):\n",
    "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
    "    return idxs\n",
    "def sample_images(data, gray, nrow):\n",
    "    idx = sample_batch(gray, bsize=nrow)\n",
    "    gray_batch = gray[idx]\n",
    "    color_batch = data[idx]\n",
    "    images = model.predict(gray_batch)\n",
    "    if np.var(images)!=0:\n",
    "        images = (images-images.min())/(images.max()-images.min())\n",
    "    cnt=1\n",
    "    for i in range(nrow):\n",
    "        plt.subplot(nrow, 3, cnt)\n",
    "        plt.imshow(color_batch[i].reshape((32, 32, 3)), cmap=\"gray\", interpolation='none')\n",
    "        plt.subplot(nrow, 3, cnt+1)\n",
    "        plt.imshow(gray_batch[i].reshape((32, 32)), cmap=\"gray\", interpolation='none')\n",
    "        plt.subplot(nrow, 3, cnt+2)\n",
    "        plt.imshow(images[i].reshape((32, 32, 3)), cmap=\"gray\", interpolation='none')\n",
    "        cnt += 3\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "35/35 [==============================] - 686s 19s/step - loss: 0.0836 - mae: 0.0984 - acc: 0.9107 - val_loss: 0.0507 - val_mae: 0.1034 - val_acc: 0.9756\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(gray_train, train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(gray_test, test))\n\u001b[0;32m----> 6\u001b[0m \u001b[43msample_images\u001b[49m(test, gray_test, \u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_images' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "for epoch in range(1, 20):\n",
    "    #display.clear_output(wait=True)\n",
    "    print('Epoch:', epoch)\n",
    "    model.fit(gray_train, train, batch_size=64, validation_data=(gray_test, test))\n",
    "    sample_images(test, gray_test, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = \"recolorising\"\n",
    "prefix = \"model\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"unet.hdf5\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m110"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
